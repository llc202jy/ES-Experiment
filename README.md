### Using Large Language Models for Event Storming: An Exploratory Study
Event Storming (ES), a cornerstone of Domain-Driven Design (DDD), is a powerful modeling technique for exploring complex business domains. Compared to traditional UML modeling techniques, ES emphasizes collaborative exploration and rapid iteration. However, its effectiveness is highly dependent on the facilitation of domain experts. Moreover, since ES sessions are typically conducted using physical or digital whiteboards, they often incur high coordination costs, especially in distributed or asynchronous settings. With the recent advances in Large Language Models (LLMs), there is growing interest in leveraging their reasoning and text generation capabilities to support software modeling tasks. This paper presents an exploratory controlled study to investigate the effectiveness of LLMs in facilitating ES modeling. We conducted a three-phase experiment involving 240 postgraduate participants: 1) manual ES, 2) LLM-based ES with basic prompts, and 3) LLM-based ES with optimized prompts. The generated models were quantitatively assessed in terms of accuracy, completeness, and consistency. The results indicate that, in ES modeling, the elements generated by LLMs are generally reliable. However, LLMs also tend to overlook or omit a substantial number of critical model elements. Carefully optimized prompts can effectively guide LLMs to infer previously overlooked elements. Nevertheless, when dealing with complex business logic, a single optimized prompt may be insufficient to improve modeling consistency.
